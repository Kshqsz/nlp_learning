# lora_sft_qwen3_1.7b.py
"""
Qwen3-1.7B LoRA SFTï¼ˆç›‘ç£å¾®è°ƒï¼‰

åœ¨ç»§ç»­é¢„è®­ç»ƒçš„æ¨¡å‹åŸºç¡€ä¸Šï¼Œä½¿ç”¨ LoRA è¿›è¡Œç›‘ç£å¾®è°ƒ
è®©æ¨¡å‹å­¦ä¼šéµå¾ªæŒ‡ä»¤ã€è¿›è¡Œå¯¹è¯

LoRA ä¼˜åŠ¿ï¼š
  - åªè®­ç»ƒ ~1% çš„å‚æ•°
  - æ˜¾å­˜å ç”¨å°ï¼Œä¸éœ€è¦ CPU Offload
  - è®­ç»ƒé€Ÿåº¦å¿«ï¼ˆ~2-3s/stepï¼‰
  - æ•ˆæœæ¥è¿‘å…¨é‡å¾®è°ƒ

è¿è¡Œæ–¹å¼ï¼š
  python lora_sft_qwen3_1.7b.py
"""
import os
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

import torch
from datasets import load_dataset
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
    DataCollatorForSeq2Seq,
)
from peft import (
    LoraConfig,
    get_peft_model,
    TaskType,
)

# ===== é…ç½® =====
# ä½¿ç”¨ç»§ç»­é¢„è®­ç»ƒåçš„æ¨¡å‹ä½œä¸ºåŸºåº§
BASE_MODEL_PATH = "./qwen3_1.7b_pretrain"  # é¢„è®­ç»ƒåçš„æ¨¡å‹
# å¦‚æœé¢„è®­ç»ƒè¿˜æ²¡å®Œæˆï¼Œå¯ä»¥å…ˆç”¨åŸå§‹æ¨¡å‹
# BASE_MODEL_PATH = "/public/huggingface-models/Qwen/Qwen3-1.7B"

OUTPUT_DIR = "./qwen3_1.7b_lora_sft"
MAX_LENGTH = 512
BATCH_SIZE = 4              # LoRA å¯ä»¥ç”¨æ›´å¤§çš„ batch
GRADIENT_ACCUMULATION_STEPS = 4  # æœ‰æ•ˆ batch = 16
LEARNING_RATE = 2e-4        # LoRA é€šå¸¸ç”¨è¾ƒå¤§å­¦ä¹ ç‡
NUM_EPOCHS = 2
NUM_SAMPLES = 10000         # SFT æ•°æ®é‡

# LoRA é…ç½®
LORA_R = 16                 # LoRA ç§©
LORA_ALPHA = 32             # ç¼©æ”¾ç³»æ•°
LORA_DROPOUT = 0.05
TARGET_MODULES = [          # Qwen3 çš„ç›®æ ‡æ¨¡å—
    "q_proj", "k_proj", "v_proj", "o_proj",
    "gate_proj", "up_proj", "down_proj",
]


# ===== 1. åŠ è½½æ¨¡å‹å’Œ Tokenizer =====
print("=" * 60)
print("ğŸš€ Qwen3-1.7B LoRA SFT å¾®è°ƒ")
print("=" * 60)
print(f"åŸºåº§æ¨¡å‹: {BASE_MODEL_PATH}")
print(f"LoRA Rank: {LORA_R}, Alpha: {LORA_ALPHA}")

print("\nğŸ“¦ åŠ è½½æ¨¡å‹...")
tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

model = AutoModelForCausalLM.from_pretrained(
    BASE_MODEL_PATH,
    trust_remote_code=True,
    torch_dtype=torch.bfloat16,
    device_map="auto",  # LoRA å¯ä»¥ç”¨ device_map
)

# æ‰“å°åŸå§‹æ¨¡å‹å‚æ•°é‡
total_params = sum(p.numel() for p in model.parameters())
print(f"åŸºåº§æ¨¡å‹å‚æ•°é‡: {total_params / 1e9:.2f}B")


# ===== 2. é…ç½® LoRA =====
print("\nğŸ”§ é…ç½® LoRA...")

lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=LORA_R,
    lora_alpha=LORA_ALPHA,
    lora_dropout=LORA_DROPOUT,
    target_modules=TARGET_MODULES,
    bias="none",
)

# åº”ç”¨ LoRA
model = get_peft_model(model, lora_config)

# å¯ç”¨ gradient checkpointingï¼ˆå¿…é¡»åœ¨åº”ç”¨ LoRA ä¹‹åï¼‰
model.enable_input_require_grads()  # å…³é”®ï¼šè®©è¾“å…¥éœ€è¦æ¢¯åº¦
model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={"use_reentrant": False})

# æ‰“å° LoRA ä¿¡æ¯
model.print_trainable_parameters()


# ===== 3. åŠ è½½ SFT æ•°æ®é›† =====
print("\nğŸ“Š åŠ è½½ SFT æ•°æ®...")

# ä»æœ¬åœ° JSONL æ–‡ä»¶åŠ è½½æ•°æ®
DATA_PATH = "./firefly-train-1.1M.jsonl"

raw_dataset = load_dataset(
    "json",
    data_files=DATA_PATH,
    split="train"
)

# å¦‚æœæ•°æ®é‡å¤§äº NUM_SAMPLESï¼Œåªå–å‰ NUM_SAMPLES æ¡
if len(raw_dataset) > NUM_SAMPLES:
    raw_dataset = raw_dataset.select(range(NUM_SAMPLES))

print(f"âœ… åŠ è½½ {len(raw_dataset)} æ¡æ•°æ®")


# ===== 4. æ•°æ®é¢„å¤„ç† =====
def preprocess_function(examples):
    """
    SFT æ•°æ®å¤„ç†ï¼šæ„å»ºå¯¹è¯æ ¼å¼
    åªå¯¹ assistant çš„å›å¤è®¡ç®— loss
    """
    input_ids_list = []
    labels_list = []
    attention_mask_list = []
    
    for kind, inp, target in zip(examples["kind"], examples["input"], examples["target"]):
        # è·³è¿‡è¿‡é•¿çš„æ ·æœ¬
        if len(inp) > 400 or len(target) > 400:
            continue
        
        # æ„å»º Qwen å¯¹è¯æ ¼å¼
        # Qwen3 ä½¿ç”¨ ChatML æ ¼å¼
        prompt = f"<|im_start|>user\n{inp}<|im_end|>\n<|im_start|>assistant\n"
        full_text = f"{prompt}{target}<|im_end|>"
        
        # Tokenize å®Œæ•´æ–‡æœ¬
        tokenized = tokenizer(
            full_text,
            max_length=MAX_LENGTH,
            truncation=True,
            padding=False,
        )
        
        input_ids = tokenized["input_ids"]
        attention_mask = tokenized["attention_mask"]
        
        # è®¡ç®— prompt é•¿åº¦ï¼Œç”¨äºæ„å»º labels
        prompt_tokens = tokenizer(prompt, add_special_tokens=False)["input_ids"]
        prompt_len = len(prompt_tokens)
        
        # Labels: prompt éƒ¨åˆ†è®¾ä¸º -100ï¼ˆä¸è®¡ç®— lossï¼‰
        labels = [-100] * prompt_len + input_ids[prompt_len:]
        
        # ç¡®ä¿é•¿åº¦ä¸€è‡´
        if len(labels) < len(input_ids):
            labels = labels + [-100] * (len(input_ids) - len(labels))
        elif len(labels) > len(input_ids):
            labels = labels[:len(input_ids)]
        
        input_ids_list.append(input_ids)
        labels_list.append(labels)
        attention_mask_list.append(attention_mask)
    
    return {
        "input_ids": input_ids_list,
        "labels": labels_list,
        "attention_mask": attention_mask_list,
    }


print("\nğŸ”„ å¤„ç†æ•°æ®...")
dataset = raw_dataset.map(
    preprocess_function,
    batched=True,
    remove_columns=raw_dataset.column_names,
    desc="Processing SFT data",
    num_proc=4,
)

# è¿‡æ»¤ç©ºæ ·æœ¬
dataset = dataset.filter(lambda x: len(x["input_ids"]) > 0)
print(f"âœ… å¤„ç†å®Œæˆï¼Œæœ‰æ•ˆæ ·æœ¬: {len(dataset)}")


# ===== 5. è®­ç»ƒé…ç½® =====
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    overwrite_output_dir=True,
    
    # è®­ç»ƒå‚æ•°
    num_train_epochs=NUM_EPOCHS,
    per_device_train_batch_size=BATCH_SIZE,
    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,
    
    # å­¦ä¹ ç‡
    learning_rate=LEARNING_RATE,
    lr_scheduler_type="cosine",
    warmup_ratio=0.05,
    
    # æ˜¾å­˜ä¼˜åŒ–
    bf16=True,
    gradient_checkpointing=False,  # å·²åœ¨æ¨¡å‹ä¸Šæ‰‹åŠ¨å¯ç”¨
    optim="adamw_torch",
    
    # æ—¥å¿—å’Œä¿å­˜
    logging_steps=20,
    save_steps=500,
    save_total_limit=2,
    
    # å…¶ä»–
    report_to="none",
    dataloader_num_workers=4,
    remove_unused_columns=True,
)


# ===== 6. å¼€å§‹è®­ç»ƒ =====
print("\n" + "=" * 60)
print("ğŸ‹ï¸ å¼€å§‹ LoRA SFT è®­ç»ƒ")
print("=" * 60)
print(f"   è®­ç»ƒæ ·æœ¬: {len(dataset)}")
print(f"   Batch Size: {BATCH_SIZE}")
print(f"   æ¢¯åº¦ç´¯ç§¯: {GRADIENT_ACCUMULATION_STEPS}")
print(f"   æœ‰æ•ˆ Batch: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}")
print(f"   Learning Rate: {LEARNING_RATE}")
print(f"   LoRA Rank: {LORA_R}")
print(f"   Epochs: {NUM_EPOCHS}")

if torch.cuda.is_available():
    print(f"   è®­ç»ƒå‰æ˜¾å­˜: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")

data_collator = DataCollatorForSeq2Seq(
    tokenizer=tokenizer,
    padding=True,
    return_tensors="pt"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    data_collator=data_collator,
)

# è®­ç»ƒ
trainer.train()


# ===== 7. ä¿å­˜ LoRA æƒé‡ =====
print(f"\nğŸ’¾ ä¿å­˜ LoRA æƒé‡åˆ° {OUTPUT_DIR}...")

model.save_pretrained(OUTPUT_DIR)
tokenizer.save_pretrained(OUTPUT_DIR)

if torch.cuda.is_available():
    peak_memory = torch.cuda.max_memory_allocated() / 1024**3
    print(f"\nğŸ“Š æ˜¾å­˜å³°å€¼: {peak_memory:.2f} GB")

print("\nâœ… LoRA SFT è®­ç»ƒå®Œæˆï¼")
print(f"ğŸ“ LoRA æƒé‡å·²ä¿å­˜åˆ°: {OUTPUT_DIR}")


# ===== 8. æµ‹è¯•å¯¹è¯æ•ˆæœ =====
print("\n" + "=" * 60)
print("ğŸ§ª æµ‹è¯•å¯¹è¯æ•ˆæœ")
print("=" * 60)

# æµ‹è¯•é—®é¢˜
test_questions = [
    "è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²",
    "å¦‚ä½•å­¦ä¹ ç¼–ç¨‹ï¼Ÿ",
    "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—",
    "Python å’Œ Java æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
]

model.eval()
for question in test_questions:
    # æ„å»ºå¯¹è¯æ ¼å¼
    prompt = f"<|im_start|>user\n{question}<|im_end|>\n<|im_start|>assistant\n"
    
    inputs = tokenizer(prompt, return_tensors="pt")
    inputs = {k: v.to(model.device) for k, v in inputs.items()}
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=200,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            repetition_penalty=1.1,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
        )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    # æå– assistant å›å¤
    if "assistant" in response:
        response = response.split("assistant")[-1].strip()
    
    print(f"\nã€é—®é¢˜ã€‘{question}")
    print(f"ã€å›ç­”ã€‘{response[:300]}...")  # æˆªæ–­æ˜¾ç¤º


print("\n" + "=" * 60)
print("ğŸ’¡ åç»­æ­¥éª¤")
print("=" * 60)
print("""
1. å¦‚éœ€åˆå¹¶ LoRA æƒé‡åˆ°åŸºåº§æ¨¡å‹ï¼Œè¿è¡Œ:
   from peft import PeftModel
   merged = model.merge_and_unload()
   merged.save_pretrained("./qwen3_1.7b_sft_merged")

2. å¦‚éœ€è¿›ä¸€æ­¥è¿›è¡Œ DPO/RLHF å¯¹é½ï¼Œå¯åŸºäºæ­¤ LoRA æ¨¡å‹ç»§ç»­è®­ç»ƒ
""")
