# chat.py - äº¤äº’å¼å¯¹è¯æœºå™¨äºº
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# ===== é…ç½® =====
# MODEL_PATH = "./qwen_pretrained"  # é¢„è®­ç»ƒæ¨¡å‹
# MODEL_PATH = "./qwen_sft"         # SFT æ¨¡å‹
MODEL_PATH = "./qwen_dpo"           # DPO æ¨¡å‹

# ===== åŠ è½½æ¨¡å‹ =====
print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_PATH}")
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_PATH,
    trust_remote_code=True,
    torch_dtype=torch.bfloat16,
    device_map="auto"
)
model.eval()

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼è®¾å¤‡: {model.device}")
print("=" * 60)

# ===== ç”Ÿæˆé…ç½® =====
GENERATION_CONFIG = {
    "max_new_tokens": 512,
    "do_sample": True,
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 50,
    "repetition_penalty": 1.1,
    "pad_token_id": tokenizer.pad_token_id,
    "eos_token_id": tokenizer.eos_token_id,
}

# ===== å¯¹è¯å†å² =====
conversation_history = []

def build_prompt(user_input: str, history: list) -> str:
    """æ„å»ºåŒ…å«å†å²çš„å¯¹è¯ prompt"""
    prompt = ""
    
    # æ·»åŠ å†å²å¯¹è¯
    for user_msg, assistant_msg in history:
        prompt += f"<|im_start|>user\n{user_msg}<|im_end|>\n"
        prompt += f"<|im_start|>assistant\n{assistant_msg}<|im_end|>\n"
    
    # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
    prompt += f"<|im_start|>user\n{user_input}<|im_end|>\n"
    prompt += "<|im_start|>assistant\n"
    
    return prompt

def chat(user_input: str, history: list) -> str:
    """ç”Ÿæˆå›å¤"""
    prompt = build_prompt(user_input, history)
    
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    
    with torch.no_grad():
        outputs = model.generate(**inputs, **GENERATION_CONFIG)
    
    # è§£ç å®Œæ•´è¾“å‡º
    full_response = tokenizer.decode(outputs[0], skip_special_tokens=False)
    
    # æå–æœ€åä¸€ä¸ª assistant å›å¤
    if "<|im_start|>assistant\n" in full_response:
        response = full_response.split("<|im_start|>assistant\n")[-1]
        # å»æ‰ç»“æŸæ ‡è®°
        if "<|im_end|>" in response:
            response = response.split("<|im_end|}")[0]
        response = response.strip()
    else:
        # fallback: ç›´æ¥æˆªå–æ–°ç”Ÿæˆçš„éƒ¨åˆ†
        response = tokenizer.decode(outputs[0][len(inputs["input_ids"][0]):], skip_special_tokens=True)
    
    return response

def main():
    global conversation_history
    
    print("ğŸ¤– Qwen ä¸­æ–‡å¯¹è¯æœºå™¨äºº")
    print("=" * 60)
    print("å‘½ä»¤è¯´æ˜:")
    print("  - è¾“å…¥é—®é¢˜å³å¯å¯¹è¯")
    print("  - è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
    print("  - è¾“å…¥ 'history' æŸ¥çœ‹å¯¹è¯å†å²")
    print("  - è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("=" * 60)
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ ä½ : ").strip()
            
            if not user_input:
                continue
            
            # ç‰¹æ®Šå‘½ä»¤
            if user_input.lower() in ["quit", "exit", "q"]:
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            if user_input.lower() == "clear":
                conversation_history = []
                print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…ç©º")
                continue
            
            if user_input.lower() == "history":
                if not conversation_history:
                    print("ğŸ“­ æš‚æ— å¯¹è¯å†å²")
                else:
                    print("\nğŸ“œ å¯¹è¯å†å²:")
                    for i, (u, a) in enumerate(conversation_history, 1):
                        print(f"  [{i}] ğŸ‘¤: {u[:50]}{'...' if len(u) > 50 else ''}")
                        print(f"      ğŸ¤–: {a[:50]}{'...' if len(a) > 50 else ''}")
                continue
            
            # ç”Ÿæˆå›å¤
            print("ğŸ¤– æ€è€ƒä¸­...", end="", flush=True)
            response = chat(user_input, conversation_history)
            print("\r" + " " * 20 + "\r", end="")  # æ¸…é™¤ "æ€è€ƒä¸­..."
            
            print(f"ğŸ¤– åŠ©æ‰‹: {response}")
            
            # ä¿å­˜åˆ°å†å²ï¼ˆæœ€å¤šä¿ç•™æœ€è¿‘ 5 è½®ï¼‰
            conversation_history.append((user_input, response))
            if len(conversation_history) > 5:
                conversation_history = conversation_history[-5:]
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()
